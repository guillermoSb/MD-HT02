---
title: "Hoja de Trabajo 02"
output: html_notebook
---

# Hoja de Trabajo 02

Librerías
```{r}
library(hopkins)
library(dplyr)
library(cluster) #Para calcular la silueta
library(e1071)#para cmeans
library(mclust) #mixtures of gaussians
library(fpc) #para hacer el plotcluster
library(NbClust) #Para determinar el número de clusters óptimo
library(factoextra) #Para hacer gráficos bonitos de clustering
library(hopkins) #Para revisar si vale la pena hacer agrupamiento
library(GGally) #Para hacer el conjunto de graficos
library(FeatureImpCluster) #Para revisar la importancia de las variables en los grupos.
library(pheatmap) #Para hacer mapa de calor
library(dplyr)

```

## 1 Prepocesamiento
```{r,warning=FALSE}
movies <- read.csv("movies.csv")

# Add release_year and release_month
years <- c(as.POSIXlt(movies$releaseDate)$year + 1900)
months <- c(as.POSIXlt(movies$releaseDate)$mon + 1)
movies$releaseYear = years
movies$releaseMonth = months

# Add average actor popularity
splittedPopularities <- strsplit(movies$actorsPopularity, "\\|")
averagePopularities <- unlist(lapply(lapply(splittedPopularities, as.numeric), mean))
movies$averageActorPopularities <- averagePopularities
movies <- na.omit(movies)

```
Resumen de columnas a utilizar para Clustering:

```{r}
print(summary(movies[,importantCols]))
```




## 2 Tendencia de Agrupamiento

``` {r}
# Define important columns for Hopkins and VAT
importantCols <- c("budget", "revenue", "popularity", "voteAvg", "genresAmount","releaseYear", "releaseMonth", "actorsAmount", "averageActorPopularities")
# Normalizar variables numericas
cols_norm <- movies[,importantCols] <- mutate_if(movies[,importantCols], is.numeric, scale)
```

### Hopkins
```{r}
seed <- 1407
set.seed(seed)
hopkins_statistichopkins_statistic <- hopkins(movies[, importantCols], m=1000)
```
El resultado del test de Hopkins es `r hopkins_statistic`, el valor es cercano a 1, según la librería que se está utilizando esto indica una tendencia a clustering alta.

### VAT

```{r}
#Matriz de distancia
datos_dist<- dist(movies[1:1000, importantCols])
fviz_dist(datos_dist, show_labels = F, gradient = list(low = "#000000", mid = "white", high = "#FC4E3F"))
```
El VAT si demuestra patrones de agrupamiento, por lo que podemos confiar en el resultado del test de Hopkins.

## 3 Determinar el numero de clusters adecuado


```{r metodo de codo factoextra}

fviz_nbclust(movies[, importantCols], kmeans, method = "wss") +
labs(subtitle = "Elbow method")
```
El número óptimo de clusters es 4. FALTA EXPANDIR

## 4. Clustering

### K-Means
```{r kmedias}
km <- kmeans(cols_norm, centers = 4, iter.max = 100) 
```

```{r}
km
```

```{r}
fviz_cluster(km, cols_norm)
```

### Clustering Jerarquico

```{r}
hc <- hc(dist(cols_norm), method = "complete")
fit <- cutree(hc, k = 4)
```

```{r}
fviz_cluster(fit, cols_norm)
```

